{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db0a5e0-97ba-4836-8fff-c809120ac1cc",
   "metadata": {},
   "source": [
    "Machine learning prototyping notebook. Data preprocessing has already been tested and implemented in data_preproc.pu (samples/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1891a377-68d5-4b9a-88ac-a76e08aaf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "# ML - preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# metrics - classification\n",
    "from sklearn.metrics import PredictionErrorDisplay, accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "\n",
    "# metrics - regression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# model comparison\n",
    "from dieboldmariano import dm_test\n",
    "\n",
    "\n",
    "# baseline models\n",
    "from sklearn import linear_model\n",
    "\n",
    "# models\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "# model persistence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a48c2-1bfe-448e-87d0-57812e39cb70",
   "metadata": {},
   "source": [
    "Decision tree regressorGet the data, split into exo/endo and perform train/test split. Get the data, split into exo/endo and perform train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d4272a8-0a9b-44d2-b0b1-413286897b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# IMPORT FUNCTIONS\n",
    "sys.path.insert(0, '../sample')\n",
    "import data_preproc\n",
    "\n",
    "# LOAD FINANCIAL RATIOS AND ASSET PRICES\n",
    "test_merge = pd.read_excel('../jupyter-notebooks/test_manual.xlsx')\n",
    "test_merge = test_merge.loc[:, test_merge.columns != 'Unnamed: 0']\n",
    "test_assets = pd.read_excel('../jupyter-notebooks/asset_prices.xlsx',index_col='Date')\n",
    "\n",
    "# PREPROCESS FINANCIAL RATIOS DATA, REPLACE STRINGS WITH FLOATS\n",
    "ML_data = test_merge.map(data_preproc.convert_placeholder_text_to_num)\n",
    "\n",
    "# ENSURE THE TWO DATAFRAMES CONTAINING FINANCIAL RATIOS (ML_DATA) AND RETURNS (TEST_ASSETS) HAVE THE SAME ASSETS/TICKERS\n",
    "ML_final = data_preproc.filter_ratios_returns(ML_data,test_assets)\n",
    "# print(ML_final.head())\n",
    "\n",
    "# RESAMPLE THE RETURNS FROM MONTHLY TO QUARTERLY, THEN BFILL AND FFILL\n",
    "asset_prices = test_assets # MAKE A COPY\n",
    "asset_prices.index = pd.to_datetime(asset_prices.index)\n",
    "asset_prices = asset_prices.resample('Q').last()\n",
    "asset_prices = asset_prices.bfill(axis=1)\n",
    "asset_prices = asset_prices.ffill(axis=1)\n",
    "\n",
    "\n",
    "# \n",
    "test = data_preproc.FRatioMLdata(ML_final,asset_prices,sector=None,returns_lead_by=2)#-1)\n",
    "#test.transform()\n",
    "#print(test.train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61a5f00e-3262-4fed-839f-7409318b443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>FCF</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Gross-Profit-Margin</th>\n",
       "      <th>Quick-Ratio</th>\n",
       "      <th>Debt / Equity</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.026975</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>-0.004744</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258930</td>\n",
       "      <td>-2.478155</td>\n",
       "      <td>4.193577</td>\n",
       "      <td>-0.806291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.309524</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.427141</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.475836</td>\n",
       "      <td>-0.002556</td>\n",
       "      <td>-0.002633</td>\n",
       "      <td>-0.002629</td>\n",
       "      <td>-1.864407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.153732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.293669</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>-0.541817</td>\n",
       "      <td>0.229405</td>\n",
       "      <td>-0.662857</td>\n",
       "      <td>-0.475000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.163001</td>\n",
       "      <td>0.155340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.825410</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>-0.064171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.049659</td>\n",
       "      <td>-1.467892</td>\n",
       "      <td>-0.094140</td>\n",
       "      <td>-0.572862</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.146119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.341260</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.026540</td>\n",
       "      <td>3.187525</td>\n",
       "      <td>0.038230</td>\n",
       "      <td>0.513707</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.029439</td>\n",
       "      <td>-0.762979</td>\n",
       "      <td>0.221575</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.089172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.117264</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.051483</td>\n",
       "      <td>-4.752607</td>\n",
       "      <td>0.241513</td>\n",
       "      <td>0.375513</td>\n",
       "      <td>-0.037037</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.075935</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.084665</td>\n",
       "      <td>-1.694389</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>-0.503057</td>\n",
       "      <td>-0.129032</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.147410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EV       FCF    EBITDA   Revenue       ROE  Gross-Profit-Margin  \\\n",
       "2  -0.026975 -0.004681 -0.004744 -0.004536  0.480392             0.000000   \n",
       "3   0.258930 -2.478155  4.193577 -0.806291  1.000000            -0.309524   \n",
       "4  -0.475836 -0.002556 -0.002633 -0.002629 -1.864407             0.000000   \n",
       "5  -0.293669 -0.008364 -0.541817  0.229405 -0.662857            -0.475000   \n",
       "6   0.825410 -0.002780 -0.002607 -0.002793 -0.064171             0.000000   \n",
       "..       ...       ...       ...       ...       ...                  ...   \n",
       "7   0.049659 -1.467892 -0.094140 -0.572862  0.232558             0.146119   \n",
       "8  -0.026540  3.187525  0.038230  0.513707  0.653846             0.531469   \n",
       "9  -0.029439 -0.762979  0.221575  0.009796  0.000000            -0.089172   \n",
       "10 -0.051483 -4.752607  0.241513  0.375513 -0.037037             0.154412   \n",
       "11 -0.084665 -1.694389  0.593941 -0.503057 -0.129032             0.054264   \n",
       "\n",
       "    Quick-Ratio  Debt / Equity   Returns  \n",
       "2      0.000000       0.000000  0.050000  \n",
       "3     -0.600000      -0.427141  0.041667  \n",
       "4      0.000000       0.000000 -0.153732  \n",
       "5      4.000000       0.163001  0.155340  \n",
       "6      0.000000       0.000000 -0.036178  \n",
       "..          ...            ...       ...  \n",
       "7      0.000000      -0.341260  0.100000  \n",
       "8      0.000000       0.034440  0.030928  \n",
       "9      0.000000      -0.117264  0.010417  \n",
       "10     0.100000       0.075935  0.185185  \n",
       "11    -0.090909      -0.147410  0.000000  \n",
       "\n",
       "[455 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the data into ML compatible format\n",
    "\n",
    "test.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff7b986d-c75b-474b-9915-4ac2b5a678f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the dataframe shuffling procedure. Ultimately, probably better to do this by invoking shuffle directly, rather than as a method of the object.\n",
    "# test.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecef3c43-9bff-4d2f-97be-5b98b3b5e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the dataframe after shuffling\n",
    "\n",
    "#test = test.train)\n",
    "data_rg = shuffle(test.train,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e243f4c1-e729-4e0e-9fe5-fc2dd02c61e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>FCF</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Gross-Profit-Margin</th>\n",
       "      <th>Quick-Ratio</th>\n",
       "      <th>Debt / Equity</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.257514</td>\n",
       "      <td>-1.889561</td>\n",
       "      <td>0.087670</td>\n",
       "      <td>-0.133416</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.575757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.209946</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>-0.243590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.364062</td>\n",
       "      <td>-6.677251</td>\n",
       "      <td>-0.008029</td>\n",
       "      <td>0.172071</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756467</td>\n",
       "      <td>-0.024635</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.085039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.098667</td>\n",
       "      <td>-0.024042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.129530</td>\n",
       "      <td>-0.949155</td>\n",
       "      <td>-3.442810</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.124476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>-0.055898</td>\n",
       "      <td>-1.656752</td>\n",
       "      <td>-0.117811</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-1.259259</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.163981</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>-0.224490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011868</td>\n",
       "      <td>-1.302406</td>\n",
       "      <td>-1.609848</td>\n",
       "      <td>-0.074476</td>\n",
       "      <td>-0.097561</td>\n",
       "      <td>-0.581081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.075949</td>\n",
       "      <td>-0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.003843</td>\n",
       "      <td>-0.464031</td>\n",
       "      <td>-0.222056</td>\n",
       "      <td>-0.209207</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>-0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.115305</td>\n",
       "      <td>2.782684</td>\n",
       "      <td>1.728695</td>\n",
       "      <td>0.443394</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>-0.088889</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>0.151899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EV       FCF    EBITDA   Revenue       ROE  Gross-Profit-Margin  \\\n",
       "9   0.257514 -1.889561  0.087670 -0.133416 -2.333333             0.175000   \n",
       "10 -0.209946  0.005086  0.005019  0.005256 -0.243590             0.000000   \n",
       "5   0.364062 -6.677251 -0.008029  0.172071  0.069444            -0.048872   \n",
       "11  0.000000 -0.756467 -0.024635 -0.002249 -0.220290             0.085039   \n",
       "5   0.129530 -0.949155 -3.442810  0.033613 -0.025641             0.461538   \n",
       "..       ...       ...       ...       ...       ...                  ...   \n",
       "5   0.018908 -0.055898 -1.656752 -0.117811  0.227273            -1.259259   \n",
       "10 -0.163981  0.005127  0.005139  0.005117 -0.224490             0.000000   \n",
       "9   0.011868 -1.302406 -1.609848 -0.074476 -0.097561            -0.581081   \n",
       "7  -0.003843 -0.464031 -0.222056 -0.209207  0.229167             0.041397   \n",
       "9  -0.115305  2.782684  1.728695  0.443394  0.062500             0.035616   \n",
       "\n",
       "    Quick-Ratio  Debt / Equity   Returns  \n",
       "9     -0.166667       0.333333  0.575757  \n",
       "10     0.000000       0.000000  0.050450  \n",
       "5     -0.050000      -0.666667  0.000000  \n",
       "11     0.000000      -0.098667 -0.024042  \n",
       "5      0.444444      -0.124476  0.000000  \n",
       "..          ...            ...       ...  \n",
       "5      2.333333       0.063901  0.333333  \n",
       "10     0.000000       0.000000  0.184783  \n",
       "9      0.000000      -0.075949 -0.016667  \n",
       "7     -0.363636       0.117647 -0.001678  \n",
       "9     -0.088889      -0.153846  0.151899  \n",
       "\n",
       "[455 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4ef76-b794-4c14-a34b-ec0568a0a2e9",
   "metadata": {},
   "source": [
    "## Tools for converting between returns and trend prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47f103ee-a541-4d88-90f7-9f72c5408e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_returns_to_category(element):\n",
    "    if element>= 0:\n",
    "        element = 1\n",
    "    if element < 0:\n",
    "        element = 0\n",
    "    return element\n",
    "\n",
    "def convert_regression_to_classification(dataframe):\n",
    "    '''\n",
    "    Given a FRatioMLdata object i.e. [ratio_1 ... ratio_n returns], convert the returns column to:\n",
    "    1 - if return >= 0\n",
    "    0 - if return < 0\n",
    "    '''\n",
    "\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    df['Returns'] = df['Returns'].map(convert_returns_to_category)\n",
    "    return df\n",
    "\n",
    "def gen_train_test(dataframe,regression=True):\n",
    "    '''\n",
    "    Need to account for different cases of regression vs classification\n",
    "    dataframe - \n",
    "    regression - \n",
    "    '''\n",
    "\n",
    "    X = dataframe.iloc[:,:-1]\n",
    "    y = dataframe.iloc[:,-1]\n",
    "    \n",
    "    # scale the data\n",
    "    data_scaler_x = StandardScaler()\n",
    "    X = data_scaler_x.fit_transform(X.values)\n",
    "\n",
    "    if regression is True:\n",
    "        data_scaler_y = StandardScaler()\n",
    "        y = data_scaler_y.fit_transform(y.values.reshape(-1,1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a83597a7-6286-4175-95a5-2ed5f3970811",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = convert_regression_to_classification(data_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c384b46-981b-41bf-a62a-d80b0e425366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>FCF</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Gross-Profit-Margin</th>\n",
       "      <th>Quick-Ratio</th>\n",
       "      <th>Debt / Equity</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.257514</td>\n",
       "      <td>-1.889561</td>\n",
       "      <td>0.087670</td>\n",
       "      <td>-0.133416</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.209946</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>-0.243590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.364062</td>\n",
       "      <td>-6.677251</td>\n",
       "      <td>-0.008029</td>\n",
       "      <td>0.172071</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756467</td>\n",
       "      <td>-0.024635</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.085039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.098667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.129530</td>\n",
       "      <td>-0.949155</td>\n",
       "      <td>-3.442810</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.124476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EV       FCF    EBITDA   Revenue       ROE  Gross-Profit-Margin  \\\n",
       "9   0.257514 -1.889561  0.087670 -0.133416 -2.333333             0.175000   \n",
       "10 -0.209946  0.005086  0.005019  0.005256 -0.243590             0.000000   \n",
       "5   0.364062 -6.677251 -0.008029  0.172071  0.069444            -0.048872   \n",
       "11  0.000000 -0.756467 -0.024635 -0.002249 -0.220290             0.085039   \n",
       "5   0.129530 -0.949155 -3.442810  0.033613 -0.025641             0.461538   \n",
       "\n",
       "    Quick-Ratio  Debt / Equity  Returns  \n",
       "9     -0.166667       0.333333        1  \n",
       "10     0.000000       0.000000        1  \n",
       "5     -0.050000      -0.666667        1  \n",
       "11     0.000000      -0.098667        0  \n",
       "5      0.444444      -0.124476        1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41b36695-8aea-459e-b7fe-4cea85136c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     1\n",
       "10    1\n",
       "5     1\n",
       "11    0\n",
       "5     1\n",
       "Name: Returns, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clf.iloc[:,-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe4a08-6e41-43b5-82b5-693c0a945bd4",
   "metadata": {},
   "source": [
    "# ML methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918cb374-7ce2-4eca-bdb0-70766c226551",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89d671f7-7f36-41c5-923d-2e4362372d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_model(model,filename):\n",
    "    '''\n",
    "    Given an sklearn model object, save the resulting model to file filename.\n",
    "    Store models in directory ../models.\n",
    "    '''\n",
    "\n",
    "    with open('../models/'+filename, 'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "    \n",
    "    # only useful to load models for testing\n",
    "    #with open('../models/test_lasso.pickle','rb') as f:\n",
    "    #    test_lasso_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdb4113a-71f4-4bd4-934e-a2cd538bb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_regress_metrics(y_test,y_pred):\n",
    "    '''\n",
    "    Given a regression type problem model (sklearn), return the following metrics as a list:\n",
    "    Mean Absolute Error (MAE)\n",
    "    Mean Squared Error (MSE)\n",
    "    R^2 error\n",
    "    Mean Absolute Percentage Error (MAPE)\n",
    "    '''\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error (MAE): {np.round(MAE, 2)}')\n",
    "\n",
    "    # Mean Squared Error (MSE)\n",
    "    MSE = mean_squared_error(y_test,y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {np.round(MSE, 2)}')\n",
    "\n",
    "    # R^2 error\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    print(f'R^2 error (test): {np.round(R2, 2)}')\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    MAPE = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)}')\n",
    "\n",
    "    return [R2, MAE, MSE, MAPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1399b1d-55c0-4e4a-879e-c64255a5a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class_metrics(y_test,y_pred):\n",
    "    '''\n",
    "    Given a regression type problem model (sklearn), return the following metrics as a list:\n",
    "    F1 Score\n",
    "    Precision Score\n",
    "    AUC\n",
    "    Accuracy Score\n",
    "    '''\n",
    "    \n",
    "    # Accuracy Score\n",
    "    AS = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy Score (test): {np.round(AS, 2)}')\n",
    "    \n",
    "    # F1 score (best 1 - worst 0)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(f'F1: {np.round(f1, 2)}')\n",
    "\n",
    "    # precision_score (the ability of the classifier not to label as positive a sample that is negative, best 1 - worst 0)\n",
    "    PS = precision_score(y_test,y_pred)\n",
    "    print(f'Precision Score: {np.round(PS, 2)}')\n",
    "\n",
    "    # roc_auc_score\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print(f'Reciever Operating Curve (Area Under Curve): {np.round(AUC, 2)}')\n",
    "\n",
    "    return [AS, f1, PS, AUC]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3905a-56fc-4802-bb22-fc906635303d",
   "metadata": {},
   "source": [
    "## Implement baseline (linear) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55f7869e-ce7d-4f41-9634-92b9b2b9ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_train_test(test,regression=True)\n",
    "X_train, X_test, y_train, y_test =  gen_train_test(data_rg,regression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19663618-4708-499b-99eb-31ce159a58fe",
   "metadata": {},
   "source": [
    "### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4b3daf8-34bc-4b26-9240-dbeaa4c2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_run(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Fit LASSO to training data and perform 5-fold CV (grid search). Return:\n",
    "    [0] - model as an object\n",
    "    [1] - metrics [R2_train, R2_test, MAE, MSE, MAPE]\n",
    "    [2] - predicted values on test set y_test\n",
    "    [3] - model as an object\n",
    "    '''\n",
    "    \n",
    "    grid = {\n",
    "        'alpha': list(np.logspace(-2, 3, 6))\n",
    "    }\n",
    "\n",
    "    reg_cv = GridSearchCV(estimator=linear_model.Lasso(), param_grid=grid,cv=5)\n",
    "    reg_cv.fit(X_train, y_train)\n",
    "\n",
    "    reg = linear_model.Lasso(alpha=reg_cv.best_params_['alpha']).fit(X_train,y_train)\n",
    "\n",
    "    y_pred_scaled = reg.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # R^2 train error\n",
    "    R2_train = reg.score(X_train, y_train)\n",
    "\n",
    "    print(f'R^2 error (train): {np.round(R2_train,5)}')\n",
    "\n",
    "    # I don't need this line because it's given in the return_regress_metrics function.\n",
    "    # print(f'R^2 error (test): {np.round(reg.score(X_test, y_test),5)}')\n",
    "\n",
    "    metrics = return_regress_metrics(y_test,y_pred)\n",
    "    metrics.insert(0,R2_train)\n",
    "\n",
    "    return reg_cv, metrics, y_pred, reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0617f1b7-6388-4769-8998-90330ad946ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error (train): 0.0\n",
      "Mean Absolute Error (MAE): 0.61\n",
      "Mean Squared Error (MSE): 1.01\n",
      "R^2 error (test): -0.0\n",
      "Mean Absolute Percentage Error (MAPE): 1.0\n"
     ]
    }
   ],
   "source": [
    "test_lasso = lasso_run(X_train, X_test, y_train, y_test)\n",
    "persist_model(test_lasso,\"LASSO.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a040724-0308-4e0c-952d-4bc982290da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to persist the model manually\n",
    "# persist_model(test_lasso[0],'test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39f55e56-652b-406a-b802-aa435e948ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented Diebold-Mariano test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ba82e29-c04b-4c44-9f1f-09d4a57da76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.27316741]), array([0.02539584]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_test(y_test, y_test, test_lasso[2], one_sided=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e58f8db9-0d1e-4d0c-ab4c-f13b02b3b3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127, -0.00056127, -0.00056127, -0.00056127, -0.00056127,\n",
       "       -0.00056127])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lasso[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b3f68-8135-4eef-ab6a-2ce5a4906de8",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71e15381-7a2b-44d7-99cc-d2c0953bae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data balance\n",
    "number_down_days = data_clf['Returns'][data_clf['Returns'] == 0].count()\n",
    "number_up_days = data_clf['Returns'][data_clf['Returns'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bc0d690-b30f-4095-99ca-813c7b94f536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_down_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed6326d7-d4b2-4b49-9bd2-614ba9db7bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_up_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9251642-21cb-4c78-b144-2a167007ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xclf_train, Xclf_test, yclf_train, yclf_test =  gen_train_test(data_clf,regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "086d17eb-4c3c-4230-ba1b-4d4d084d16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_run(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Fit Logistic Regression model to training data and perform 5-fold CV (grid search). Return:\n",
    "    [0] - model as an object\n",
    "    [1] - metrics [AS train, AS test, f1, PS]\n",
    "    [2] - predicted values on test set y_test\n",
    "    [3] - model as an object\n",
    "    '''\n",
    "    \n",
    "    grid = [\n",
    "        {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': list(np.logspace(-2, 3, 6)),\n",
    "            'solver':['saga']\n",
    "        \n",
    "    },\n",
    "        {\n",
    "         'penalty': ['elasticnet'],\n",
    "            'C': list(np.logspace(-2, 3, 6)),\n",
    "            'l1_ratio': list(np.linspace(0,1,5)),\n",
    "            'solver':['saga']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    log_cv = GridSearchCV(estimator=linear_model.LogisticRegression(), param_grid=grid,cv=5)\n",
    "    log_cv.fit(X_train, y_train) # fit(X_train,np.ravel(y_train))\n",
    "\n",
    "    log = linear_model.LogisticRegression(penalty=log_cv.best_params_['penalty'],\\\n",
    "                                          C=log_cv.best_params_['C'],l1_ratio=log_cv.best_params_['l1_ratio'],\\\n",
    "                                         solver='saga').fit(X_train,y_train)\n",
    "\n",
    "    y_pred_scaled = log.predict(X_test)\n",
    "    y_pred = y_pred_scaled\n",
    "\n",
    "    # Accuracy score on training set\n",
    "    AS_train = log.score(X_train, y_train)\n",
    "\n",
    "    print(f'Accuracy Score (train): {np.round(AS_train,5)}')\n",
    "\n",
    "    metrics = return_class_metrics(y_test,y_pred)\n",
    "    metrics.insert(0,AS_train)\n",
    "\n",
    "    return log_cv, metrics, y_pred, log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90529a28-cd08-4a2f-b167-d6a119eef298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (train): 0.5467\n",
      "Accuracy Score (test): 0.49\n",
      "F1: 0.66\n",
      "Precision Score: 0.49\n",
      "Reciever Operating Curve (Area Under Curve): 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_logistic = logistic_run(Xclf_train, Xclf_test, yclf_train, yclf_test)\n",
    "persist_model(test_logistic,\"Logistic.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20cc75-d40a-41e3-970a-8cdee543fe30",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6dc3d-098a-40c0-9670-ab34c1ddb596",
   "metadata": {},
   "source": [
    "### SVM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac511638-7f1f-4715-a7ff-267541437f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVR_run(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Fit SVM regression to training data and perform 5-fold CV (grid search). Return:\n",
    "    [0] - model_cv as an object\n",
    "    [1] - metrics [R2_train, R2_test, MAE, MSE, MAPE]\n",
    "    [2] - predicted values on test set y_test\n",
    "    [3] - model as an object\n",
    "\n",
    "    Finally, save the model to a pickle file\n",
    "    '''\n",
    "\n",
    "    grid = {\n",
    "        'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "        'C': list(np.logspace(-2, 3, 6)), \n",
    "        'epsilon': [0.01,0.1,1,10]\n",
    "    }\n",
    "\n",
    "    svr_cv = GridSearchCV(estimator=svm.SVR(), param_grid=grid,cv=5,n_jobs=4)\n",
    "    svr_cv.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    svr = svm.SVR(kernel=svr_cv.best_params_['kernel'],C=svr_cv.best_params_['C'],epsilon=svr_cv.best_params_['epsilon']).fit(X_train,y_train)\n",
    "\n",
    "    y_pred_scaled = svr.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # R^2 train error\n",
    "    R2_train = svr.score(X_train, y_train)\n",
    "\n",
    "    print(f'R^2 error (train): {np.round(R2_train,5)}')\n",
    "\n",
    "    metrics = return_regress_metrics(y_test,y_pred)\n",
    "    metrics.insert(0,R2_train)\n",
    "\n",
    "    return svr_cv, metrics, y_pred, svr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f81e96fe-ce65-4af7-bee6-c38643be9acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error (train): -0.00771\n",
      "Mean Absolute Error (MAE): 0.57\n",
      "Mean Squared Error (MSE): 1.03\n",
      "R^2 error (test): -0.02\n",
      "Mean Absolute Percentage Error (MAPE): 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "ml_svr = SVR_run(X_train, X_test, y_train, y_test)\n",
    "persist_model(ml_svr,\"ml_svr.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18052898-ca8d-4ea1-8145-2963b6262f3f",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a9bbf-63c8-4a70-8fef-1181cec1ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTR_run(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Fit Decision Tree regression to training data and perform 5-fold CV (grid search). Return:\n",
    "    [0] - model_cv as an object\n",
    "    [1] - metrics [R2_train, R2_test, MAE, MSE, MAPE]\n",
    "    [2] - predicted values on test set y_test\n",
    "    [3] - model as an object\n",
    "\n",
    "    Finally, save the model to a pickle file\n",
    "    '''\n",
    "\n",
    "    grid = {\n",
    "        'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "        'C': list(np.logspace(-2, 3, 6)), \n",
    "        'epsilon': [0.01,0.1,1,10]\n",
    "    }\n",
    "\n",
    "    svr_cv = GridSearchCV(estimator=svm.SVR(), param_grid=grid,cv=5,n_jobs=4)\n",
    "    svr_cv.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    svr = svm.SVR(kernel=svr_cv.best_params_['kernel'],C=svr_cv.best_params_['C'],epsilon=svr_cv.best_params_['epsilon']).fit(X_train,y_train)\n",
    "\n",
    "    y_pred_scaled = svr.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "    # R^2 train error\n",
    "    R2_train = svr.score(X_train, y_train)\n",
    "\n",
    "    print(f'R^2 error (train): {np.round(R2_train,5)}')\n",
    "\n",
    "    metrics = return_regress_metrics(y_test,y_pred)\n",
    "    metrics.insert(0,R2_train)\n",
    "\n",
    "    return svr_cv, metrics, y_pred, svr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f15789-f633-44d7-a7c7-bfe15db9f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_features': ['sqrt', 'log2',None],\n",
    "    'max_depth' : [3,4,5,6,7,8, None],\n",
    "    'ccp_alpha': list(np.logspace(-2, 3, 6)),\n",
    "    'random_state' : [0]\n",
    "}\n",
    "\n",
    "DTR_cv = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=grid,cv=5)\n",
    "DTR_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad5691-6949-4ec2-86e8-8e7d4f18e711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb0b0b-a58f-459f-8957-4838ad67e92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0bb1c7-a086-4735-b256-d96081774465",
   "metadata": {},
   "source": [
    "## Support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d76183c-5205-4065-b99f-45d3c278ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_train_test(test,regression=True)\n",
    "X_train, X_test, y_train, y_test =  gen_train_test(data_clf,regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb3837c-9659-413f-9dab-4cccab206602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functionalise SVC\n",
    "\n",
    "def SVC_run(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    '''\n",
    "    # define grid of parameters to search\n",
    "    grid = {\n",
    "        'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "        'C': list(np.logspace(-2, 3, 6)), \n",
    "        'degree': [3]\n",
    "    }\n",
    "    \n",
    "    SVC_cv = GridSearchCV(estimator=SVC(), param_grid=grid,cv=5)\n",
    "    SVC_cv.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "    svc = SVC(C=SVC_cv.best_params_['C'], kernel=SVC_cv.best_params_['kernel']).fit(X_train,y_train)\n",
    "\n",
    "    # get predicted values (out of sample performance)\n",
    "    y_pred_scaled = svc.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "    \n",
    "    print(f'R^2 error (train): {np.round(svc.score(X_train, y_train),5)}')\n",
    "    print(f'R^2 error (test): {np.round(svc.score(X_test, y_test),5)}')\n",
    "    \n",
    "    AS = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy score: {np.round(AS, 2)}')\n",
    "\n",
    "    return SVC_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6cfac6f-1352-4455-ba1c-5a456cffdc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error (train): 0.55495\n",
      "R^2 error (test): 0.56044\n",
      "Accuracy score: 0.56\n"
     ]
    }
   ],
   "source": [
    "test_svc = SVC_run(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1cfdbd-095a-4c7f-b935-4cded0ccd77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0, 'degree': 3, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3a17aca-476b-4db5-8775-cef347b82840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c719b-d32e-4d9c-a720-32af2b194cc3",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02d3f39e-07a7-4c9e-8635-addac2d6c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functionalise decision tree classifier\n",
    "\n",
    "def tree_class(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    '''\n",
    "    grid = {\n",
    "        'max_features': ['sqrt', 'log2',None],\n",
    "        'max_depth' : [3,4,5,6,7,8, None],\n",
    "        'ccp_alpha': list(np.logspace(-2, 3, 6)),\n",
    "        'random_state' : [0]\n",
    "    }\n",
    "    \n",
    "    DTC_cv = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=grid,cv=5)\n",
    "    DTC_cv.fit(X_train,y_train)\n",
    "\n",
    "    dtc = DecisionTreeClassifier(ccp_alpha=DTC_cv.best_params_['ccp_alpha'], max_depth=DTC_cv.best_params_['max_depth'],\\\n",
    "                                 max_features=DTC_cv.best_params_['max_features'],random_state=0).fit(X_train,y_train)\n",
    "    \n",
    "    # get predicted values (out of sample performance)\n",
    "    y_pred_scaled = dtc.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "    \n",
    "    print(f'R^2 error (train): {np.round(dtc.score(X_train, y_train),5)}')\n",
    "    print(f'R^2 error (test): {np.round(dtc.score(X_test, y_test),5)}')\n",
    "    \n",
    "    # Mean Absolute Error (MAE)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error (MAE): {np.round(MAE, 2)}')\n",
    "    \n",
    "    # Mean Squared Error (MSE)\n",
    "    MSE = mean_squared_error(y_test,y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {np.round(MSE, 2)}')\n",
    "\n",
    "    return DTC_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b57a188d-f046-4dd2-b99b-b83eca7a95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error (train): 0.67582\n",
      "R^2 error (test): 0.62637\n",
      "Mean Absolute Error (MAE): 0.37\n",
      "Mean Squared Error (MSE): 0.37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;random_state&#x27;: [0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;random_state&#x27;: [0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'ccp_alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 8, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'random_state': [0]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_class(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ace456-00b4-4e60-944f-a92a65997205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f6835-7cb3-4af7-b2f3-785ca499b25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebb8b8-d2d5-4baa-a76d-c20cdec25f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_cv.best_params_['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0d0f7-1cab-409d-ba08-5cfa514b6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "    SVC_cv = GridSearchCV(estimator=SVC(), param_grid=grid,cv=5)\n",
    "    SVC_cv.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "    svc = SVC(C=SVC_cv.best_params_['C'], kernel=SVC_cv.best_params_['kernel']).fit(X_train,y_train)\n",
    "\n",
    "    # get predicted values (out of sample performance)\n",
    "    y_pred_scaled = svc.predict(X_test)\n",
    "    y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "    \n",
    "    print(f'R^2 error (train): {np.round(svc.score(X_train, y_train),5)}')\n",
    "    print(f'R^2 error (test): {np.round(svc.score(X_test, y_test),5)}')\n",
    "    \n",
    "    AS = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy score: {np.round(AS, 2)}')\n",
    "\n",
    "    return SVC_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df551f2-1788-4315-8dea-b2cd6d580a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352825fd-f62e-49e9-b736-c85bde5d4e7d",
   "metadata": {},
   "source": [
    "# (obsolete) Tensorflow tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08cae8c1-fba9-455a-bfe5-d1b7bda4e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 04:53:44.238854: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 04:53:44.539484: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 04:53:44.547219: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 04:53:47.890604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55945887-7ca5-469a-9247-e25eb214337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "step = 6\n",
    "\n",
    "past = 2\n",
    "future = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4aac96-c866-48f5-8594-ab09ea7621c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The selected parameters are:\",\n",
    "    \", \".join([titles[i] for i in [0, 1, 5, 7, 8, 10, 11]]),\n",
    ")\n",
    "selected_features = [feature_keys[i] for i in [0, 1, 5, 7, 8, 10, 11]]\n",
    "features = df[selected_features]\n",
    "features.index = df[date_time_key]\n",
    "features.head()\n",
    "\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "features.head()\n",
    "\n",
    "train_data = features.loc[0 : train_split - 1]\n",
    "val_data = features.loc[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333551ca-e26b-4407-9cad-d55991089b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(7)]].values\n",
    "y_train = features.iloc[start:end][[1]]\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b30c94-ed2e-4321-9453-dd36fa735792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d34adc91-0652-4610-9aa7-1b37254ea5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EV</th>\n",
       "      <th>FCF</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Gross-Profit-Margin</th>\n",
       "      <th>Quick-Ratio</th>\n",
       "      <th>Debt / Equity</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.360803</td>\n",
       "      <td>3.447233</td>\n",
       "      <td>6.393835</td>\n",
       "      <td>2.463991</td>\n",
       "      <td>-0.617978</td>\n",
       "      <td>-0.194444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.167730</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>1.383396</td>\n",
       "      <td>2.139292</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.105882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.118467</td>\n",
       "      <td>-1.077758</td>\n",
       "      <td>3.322930</td>\n",
       "      <td>3.002712</td>\n",
       "      <td>-0.160714</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.828341</td>\n",
       "      <td>2.425314</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.105485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.137338</td>\n",
       "      <td>8.858668</td>\n",
       "      <td>0.814978</td>\n",
       "      <td>1.140352</td>\n",
       "      <td>1.397833</td>\n",
       "      <td>-0.107325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.289474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.215536</td>\n",
       "      <td>2.891626</td>\n",
       "      <td>2.661053</td>\n",
       "      <td>2.845256</td>\n",
       "      <td>0.221519</td>\n",
       "      <td>-0.020891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.085798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.235294</td>\n",
       "      <td>0.717772</td>\n",
       "      <td>2.678497</td>\n",
       "      <td>3.650943</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>-0.070866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.141936</td>\n",
       "      <td>1.516245</td>\n",
       "      <td>2.951967</td>\n",
       "      <td>2.931063</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>-0.039634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.163367</td>\n",
       "      <td>1.601319</td>\n",
       "      <td>3.884052</td>\n",
       "      <td>2.301454</td>\n",
       "      <td>-0.113924</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.341322</td>\n",
       "      <td>-66.739179</td>\n",
       "      <td>-7.620575</td>\n",
       "      <td>1.043916</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.536267</td>\n",
       "      <td>-4.212453</td>\n",
       "      <td>-0.433195</td>\n",
       "      <td>3.356550</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.078388</td>\n",
       "      <td>2.750239</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>3.317109</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.023555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057880</td>\n",
       "      <td>2.839728</td>\n",
       "      <td>-1.364142</td>\n",
       "      <td>2.875472</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.239613</td>\n",
       "      <td>2.377237</td>\n",
       "      <td>4.915254</td>\n",
       "      <td>3.172105</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.053452</td>\n",
       "      <td>4.842591</td>\n",
       "      <td>2.154152</td>\n",
       "      <td>2.582387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.062592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140845</td>\n",
       "      <td>2.592014</td>\n",
       "      <td>2.050364</td>\n",
       "      <td>1.811490</td>\n",
       "      <td>-0.729622</td>\n",
       "      <td>0.080160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.288231</td>\n",
       "      <td>3.725208</td>\n",
       "      <td>3.803072</td>\n",
       "      <td>2.797645</td>\n",
       "      <td>0.199588</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.024801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.210107</td>\n",
       "      <td>3.763671</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.031294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037594</td>\n",
       "      <td>3.729276</td>\n",
       "      <td>1.754967</td>\n",
       "      <td>3.405174</td>\n",
       "      <td>-0.296296</td>\n",
       "      <td>-0.122807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.313666</td>\n",
       "      <td>-0.576501</td>\n",
       "      <td>-5.161124</td>\n",
       "      <td>3.271994</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.303306</td>\n",
       "      <td>2.213588</td>\n",
       "      <td>33.556288</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>-0.194483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638622</td>\n",
       "      <td>0.594837</td>\n",
       "      <td>2.683060</td>\n",
       "      <td>2.862259</td>\n",
       "      <td>-0.162313</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033803</td>\n",
       "      <td>0.188576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.941286</td>\n",
       "      <td>-4.047730</td>\n",
       "      <td>2.341291</td>\n",
       "      <td>2.053891</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171654</td>\n",
       "      <td>6.727141</td>\n",
       "      <td>1.947216</td>\n",
       "      <td>3.023713</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.016985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.169625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.235953</td>\n",
       "      <td>3.467655</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.084388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.544118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.667479</td>\n",
       "      <td>3.136463</td>\n",
       "      <td>-2.750000</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065875</td>\n",
       "      <td>1.578933</td>\n",
       "      <td>2.548325</td>\n",
       "      <td>2.629238</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.035990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.052277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.410157</td>\n",
       "      <td>0.645540</td>\n",
       "      <td>2.085831</td>\n",
       "      <td>2.786320</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.502139</td>\n",
       "      <td>4.666506</td>\n",
       "      <td>3.444186</td>\n",
       "      <td>3.539031</td>\n",
       "      <td>-0.144928</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.260537</td>\n",
       "      <td>1.299610</td>\n",
       "      <td>16.463261</td>\n",
       "      <td>2.036351</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>-7.536585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.081291</td>\n",
       "      <td>-5.295619</td>\n",
       "      <td>4.452068</td>\n",
       "      <td>3.840574</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.033962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.103093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.310436</td>\n",
       "      <td>-4.514237</td>\n",
       "      <td>1.925869</td>\n",
       "      <td>2.771210</td>\n",
       "      <td>-0.126984</td>\n",
       "      <td>-0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.383659</td>\n",
       "      <td>1.366359</td>\n",
       "      <td>2.841611</td>\n",
       "      <td>2.762465</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>-0.024242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211474</td>\n",
       "      <td>-1.724880</td>\n",
       "      <td>3.028702</td>\n",
       "      <td>3.145749</td>\n",
       "      <td>-0.348485</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.042396</td>\n",
       "      <td>5.560582</td>\n",
       "      <td>14.872640</td>\n",
       "      <td>3.174558</td>\n",
       "      <td>-0.232143</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.057167</td>\n",
       "      <td>-7.518921</td>\n",
       "      <td>3.198545</td>\n",
       "      <td>3.074680</td>\n",
       "      <td>-0.050684</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052414</td>\n",
       "      <td>16.933230</td>\n",
       "      <td>3.938400</td>\n",
       "      <td>4.459870</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.330586</td>\n",
       "      <td>3.879828</td>\n",
       "      <td>3.304568</td>\n",
       "      <td>3.134571</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.299020</td>\n",
       "      <td>3.103672</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761468</td>\n",
       "      <td>1.621310</td>\n",
       "      <td>0.525466</td>\n",
       "      <td>3.132839</td>\n",
       "      <td>-1.231343</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.755057</td>\n",
       "      <td>2.825058</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>-0.131250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.076962</td>\n",
       "      <td>3.781239</td>\n",
       "      <td>2.274945</td>\n",
       "      <td>3.248143</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>-0.099138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.163570</td>\n",
       "      <td>-0.926259</td>\n",
       "      <td>2.188190</td>\n",
       "      <td>3.109451</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.120332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.277400</td>\n",
       "      <td>-12.897155</td>\n",
       "      <td>-0.439825</td>\n",
       "      <td>2.636294</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>-0.084249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.198413</td>\n",
       "      <td>3.386457</td>\n",
       "      <td>3.511200</td>\n",
       "      <td>3.490347</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>-0.051887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.548132</td>\n",
       "      <td>2.987514</td>\n",
       "      <td>-0.007576</td>\n",
       "      <td>-0.035176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EV        FCF     EBITDA   Revenue       ROE  Gross-Profit-Margin  \\\n",
       "0  -0.360803   3.447233   6.393835  2.463991 -0.617978            -0.194444   \n",
       "0  -0.167730   2.071429   1.383396  2.139292 -0.034483             0.196581   \n",
       "0  -0.118467  -1.077758   3.322930  3.002712 -0.160714            -0.015000   \n",
       "0   0.168897   0.000000   2.828341  2.425314 -0.166667             0.105485   \n",
       "0  -0.137338   8.858668   0.814978  1.140352  1.397833            -0.107325   \n",
       "0  -0.215536   2.891626   2.661053  2.845256  0.221519            -0.020891   \n",
       "0  -0.235294   0.717772   2.678497  3.650943 -0.103448            -0.070866   \n",
       "0   1.141936   1.516245   2.951967  2.931063  0.174757            -0.039634   \n",
       "0   2.163367   1.601319   3.884052  2.301454 -0.113924             0.039002   \n",
       "0  -0.341322 -66.739179  -7.620575  1.043916 -0.166667             0.091667   \n",
       "0   0.536267  -4.212453  -0.433195  3.356550 -3.666667             0.415730   \n",
       "0  -0.078388   2.750239   3.875000  3.317109  0.031250            -0.023555   \n",
       "0   0.057880   2.839728  -1.364142  2.875472 -0.062500            -0.171875   \n",
       "0  -0.239613   2.377237   4.915254  3.172105  0.307018            -0.019257   \n",
       "0  -0.053452   4.842591   2.154152  2.582387  0.000000            -0.050725   \n",
       "0  -0.140845   2.592014   2.050364  1.811490 -0.729622             0.080160   \n",
       "0   2.288231   3.725208   3.803072  2.797645  0.199588             0.049080   \n",
       "0  -1.024801   0.000000  -5.210107  3.763671  4.250000             0.031294   \n",
       "0   0.037594   3.729276   1.754967  3.405174 -0.296296            -0.122807   \n",
       "0   0.313666  -0.576501  -5.161124  3.271994  0.067797             0.005252   \n",
       "0   1.303306   2.213588  33.556288  3.650000  0.223022            -0.194483   \n",
       "0   0.638622   0.594837   2.683060  2.862259 -0.162313             0.011905   \n",
       "0  -0.941286  -4.047730   2.341291  2.053891  0.032258             0.000000   \n",
       "0   0.171654   6.727141   1.947216  3.023713  0.046875             0.016985   \n",
       "0  -0.169625   0.000000   3.235953  3.467655  0.333333             0.084388   \n",
       "0   0.278893   0.000000   2.667479  3.136463 -2.750000             0.030960   \n",
       "0  -0.065875   1.578933   2.548325  2.629238  0.153846             0.035990   \n",
       "0   2.410157   0.645540   2.085831  2.786320  0.703704            -0.020566   \n",
       "0  -0.502139   4.666506   3.444186  3.539031 -0.144928             0.135484   \n",
       "0  -0.260537   1.299610  16.463261  2.036351  0.017544            -7.536585   \n",
       "0  -0.081291  -5.295619   4.452068  3.840574 -3.000000            -0.033962   \n",
       "0  -0.310436  -4.514237   1.925869  2.771210 -0.126984            -0.034188   \n",
       "0  -0.383659   1.366359   2.841611  2.762465  0.246753            -0.024242   \n",
       "0   0.211474  -1.724880   3.028702  3.145749 -0.348485             0.048485   \n",
       "0  -0.042396   5.560582  14.872640  3.174558 -0.232143            41.000000   \n",
       "0  -0.057167  -7.518921   3.198545  3.074680 -0.050684             0.450704   \n",
       "0  -0.052414  16.933230   3.938400  4.459870  0.560976             0.345133   \n",
       "0  -0.330586   3.879828   3.304568  3.134571  0.040816             0.067485   \n",
       "0   0.241358   0.000000   3.299020  3.103672  0.266667             0.026699   \n",
       "0   0.761468   1.621310   0.525466  3.132839 -1.231343            -0.113445   \n",
       "0   0.087814   0.000000   3.755057  2.825058  0.026786            -0.131250   \n",
       "0  -0.076962   3.781239   2.274945  3.248143  0.615385            -0.099138   \n",
       "0  -0.163570  -0.926259   2.188190  3.109451 -0.054945             0.487179   \n",
       "0  15.277400 -12.897155  -0.439825  2.636294  1.769231            -0.084249   \n",
       "0  -0.198413   3.386457   3.511200  3.490347 -0.033520            -0.051887   \n",
       "0   0.127666   0.000000   2.548132  2.987514 -0.007576            -0.035176   \n",
       "\n",
       "   Quick-Ratio  Debt / Equity   Returns  \n",
       "0          0.0       0.000000  0.041667  \n",
       "0          0.0       0.000000 -0.105882  \n",
       "0          0.0       0.000000  0.269761  \n",
       "0          0.0       0.000000 -0.018919  \n",
       "0          0.0       0.000000 -0.289474  \n",
       "0          0.0       0.000000 -0.085798  \n",
       "0          0.0       0.000000  0.000713  \n",
       "0          0.0       0.000000  0.214325  \n",
       "0          0.0       0.000000  0.735849  \n",
       "0          0.0       0.000000  0.052632  \n",
       "0          0.0       0.000000  0.373134  \n",
       "0          0.0       0.000000  0.076874  \n",
       "0          0.0       0.000000 -0.052632  \n",
       "0          0.0       0.000000  0.100775  \n",
       "0          0.0       0.000000 -0.062592  \n",
       "0          0.0       0.000000 -0.057143  \n",
       "0          0.0       0.000000  0.660377  \n",
       "0          0.0       0.000000  0.168098  \n",
       "0          0.0       0.000000 -0.040001  \n",
       "0          0.0       0.000000  0.563218  \n",
       "0          0.0       0.000000  0.120000  \n",
       "0          0.0      -0.033803  0.188576  \n",
       "0          0.0       0.000000 -0.047059  \n",
       "0          0.0       0.000000  0.187500  \n",
       "0          0.0       0.000000 -0.544118  \n",
       "0          0.0       0.000000  0.118750  \n",
       "0          0.0       0.000000 -0.052277  \n",
       "0          0.0       0.000000  0.126780  \n",
       "0          0.0       0.000000 -0.270270  \n",
       "0          0.0       0.000000 -0.075000  \n",
       "0          0.0       0.000000 -0.103093  \n",
       "0          0.0       0.000000  0.077844  \n",
       "0          0.0       0.000000  0.072184  \n",
       "0          0.0       0.000000  0.104780  \n",
       "0          0.0       0.000000  0.342391  \n",
       "0          0.0       0.000000  0.109375  \n",
       "0          0.0       0.000000  0.047619  \n",
       "0          0.0       0.000000 -0.067797  \n",
       "0          0.0       0.000000  0.000000  \n",
       "0          0.0       0.000000  0.324503  \n",
       "0          0.0       0.000000  0.112500  \n",
       "0          0.0       0.000000  0.018868  \n",
       "0          0.0       0.000000 -0.120332  \n",
       "0          0.0       0.000000  2.079470  \n",
       "0          0.0       0.000000  0.049476  \n",
       "0          0.0       0.000000 -0.024097  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.train[test.train.index == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165543a-6e3c-409b-9a41-994c6fd48cce",
   "metadata": {},
   "source": [
    "# Prototype code, unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330758b7-e82d-46fe-b376-1e741ce4fbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7606c227-b17e-426c-add4-9d9811e14c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt SVM\n",
    "grid = {\n",
    "    'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "    'C': [0.01,0.1,1,10], \n",
    "}\n",
    "\n",
    "SVC_cv = GridSearchCV(estimator=SVC(), param_grid=grid,cv=5)\n",
    "SVC_cv.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16cace2a-5641-4f1f-804b-187bb3ca304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "645325a1-5d79-483f-9e17-4c8fa11fdc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_cv.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "111a2d44-7e17-44d0-8e32-a2f3800700ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error (train): 0.58716\n",
      "R^2 error (test): 0.52727\n",
      "Accuracy score: 0.53\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=SVC_cv.best_params_['C'], kernel=SVC_cv.best_params_['kernel']).fit(X_train,y_train)\n",
    "\n",
    "# get predicted values (out of sample performance)\n",
    "y_pred_scaled = svc.predict(X_test)\n",
    "y_pred = y_pred_scaled#data_scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))\n",
    "\n",
    "print(f'R^2 error (train): {np.round(svc.score(X_train, y_train),5)}')\n",
    "print(f'R^2 error (test): {np.round(svc.score(X_test, y_test),5)}')\n",
    "\n",
    "AS = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score: {np.round(AS, 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27e7774-0357-4d3d-b9b6-834c7760fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;random_state&#x27;: [0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;random_state&#x27;: [0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'ccp_alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 8, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'random_state': [0]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt decision tree classifier\n",
    "\n",
    "grid = {\n",
    "    'max_features': ['sqrt', 'log2',None],\n",
    "    'max_depth' : [3,4,5,6,7,8, None],\n",
    "    'ccp_alpha': list(np.logspace(-2, 3, 6)),\n",
    "    'random_state' : [0]\n",
    "}\n",
    "\n",
    "DTR_cv = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=grid,cv=5)\n",
    "DTR_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f3dfe29-42be-48d8-9212-8977b500e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66faf605-71d0-4b64-96a0-89f80e7721de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
